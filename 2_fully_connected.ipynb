{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully-connected Neural Networks with Keras\n",
    "\n",
    "As part of this tutorial, we are going to revist the MNIST image classification use case using classical fully-connected (also dense) artificial neural networks (FC-NN, Dense-NN). In the basic form of such a neural network, each of the neurons in the network is a single logistic regression. We employ multiple of these units in order to be able to model highly complex, non-linear separation boundaries between individual classes (see also the XOR-problem).\n",
    "\n",
    "Thereby, the individual neurons are usually arranged in so-called layers that connected with each other in a directed acyclic structure. There are usually at least two layers, the input and output layer, where the data samples are passed in, and the prediction read out respectively. Additionally, there may be a number of hidden layers, additional logistic regression units, allowing to model higher-order functions. Each of the neurons within a layer is connected to every unit of the previous and subsequent layer, implementing a layer-wise full (hence the name) connectivity. Having more than one hidden unit is bluntly put deep-learning.\n",
    "\n",
    "![FCNN](images/fc-nn.png)\n",
    "<div align=\"center\" style=\"color: #aaaaaa; font-size: 0.7em;\">© Medium.com [1]</div>\n",
    "\n",
    "\n",
    "### Setup\n",
    "\n",
    "For a detailed explanation of the use modules, please refer to the respective sections in the [introductory notebook](0_MNIST_dataset.ipynb) and the one on [logistic regression](1_logistic_regression.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.set_random_seed(SEED)\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data\n",
    "\n",
    "We will once again load the MNIST database from the HDF5 file. For details, please also see the [introductory notebook](MNIST dataset.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path='mnist.h5'):\n",
    "    \"\"\"\n",
    "    Loads a dataset and its supervisor labels from the HDF5 file specified by the path.\n",
    "    It is assumed that the HDF5 dataset containing the data is called 'data' and the labels are called 'labels'.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str, optional\n",
    "        The absolute or relative path to the HDF5 file, defaults to mnist.h5.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_and_labels : tuple(np.array[samples, width, height], np.array[samples])\n",
    "        a tuple with two numpy array containing the data and labels\n",
    "    \"\"\"\n",
    "    with h5py.File(path, 'r') as handle:\n",
    "        return np.array(handle['/data']), np.array(handle['/labels'])\n",
    "    \n",
    "data, labels = load_data()\n",
    "data.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Data\n",
    "\n",
    "Just like in the logistic regression tutorial, we consider each of the individual pixels of an image as one of the features of our classical problem. This means, we will again flatten the image into a long vector of 28 x 28 = 784 elements. \n",
    "\n",
    "Additionally, we will from now on also only consider the multiclass classification problem, of identifying for all image the correct digit class from all of the available ten. Therefore, we need to think about how we encode our supervisor labels. The naïve approach would be to have a single output neuron and let it simply predict the number it thinks it depicted in the image. This approach, however, has two major downsides. First, the output neuron value range would be unbound, and a prediction of say *-1* or *11* could be reasonably expected. Second, in an output format like this some numbers would be illogically more similar to each other (due to their absolute difference) than they are in reality. The digit *7* for example would be very similar to *6* and *8* and not to *1*.\n",
    "\n",
    "To counteract this effect, we are going to choose a different label encoding instead. For each samples, we will translate the label into a vector that is as long as the number of unique classes (here: 10). Each of the positions in the vector is uniquely associated with one of the individual classes and is set to 1 if the data sample is member of the respective class and 0 otherwise. Using this encoding, also called one-hot-encoding [2], each class has the same distance to every other class and we can additionally interpret the output again to be the probability of the data item belonging to each individual class.\n",
    "\n",
    "\\begin{align}\n",
    "1 & \\rightarrow [0, 1, 0, 0, 0, 0, 0, 0, 0, 0] \\\\\n",
    "7 & \\rightarrow [0, 0, 0, 0, 0, 0, 0, 1, 0, 0] \n",
    "\\end{align}\n",
    "\n",
    "One of the downsides of the proposed one-hot encoding method is a significantly increased memory footprint. In large-scale machine learning applications it might be necessary to use techniques like embedding or sparse matrix formats for the proper output encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, labels):\n",
    "    \"\"\"\n",
    "    Flattens the each image in the data to be a one-dimensional feature vector and encodes the labels in one-hot encoding.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.array[samples, width, height]\n",
    "        the image dataset\n",
    "    labels : np.array[samples]\n",
    "        the corresponding labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_and_labels : tuple(np.array[samples, width * height], np.array[samples, classes])\n",
    "        a tuple with two numpy array containing the flattened data and one-hot encoded labels\n",
    "    \"\"\"\n",
    "    return data.reshape(data.shape[0], -1), to_categorical(labels)\n",
    "\n",
    "preprocessed_data, preprocessed_labels = preprocess_data(data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Test Dataset Partitioning\n",
    "\n",
    "In order to be able to judge whether our machine learning algorithm actually learns a pattern and does not simply memorize the training data, we need to verify whether it is able to correctly predict unseen or \"new\" data. One way of emulating this behaviour, is to artificially split the whole input dataset into disjoint training and test data (sometimes additionally validation data for model hyperparameter optimization) and use the former for adjusting the internal model parameters and the latter for testing the out-of-sample performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(data, labels, train_fraction=0.8):\n",
    "    \"\"\"\n",
    "    Flattens the each image in the data to be a one-dimensional feature vector and encodes the labels in one-hot encoding.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.array[samples, width * height]\n",
    "        the image dataset\n",
    "    labels : np.array[samples, classes]\n",
    "        the corresponding labels\n",
    "    train_fraction : float, optional\n",
    "        the fraction between in [0.0, 1.0] of data items beeing assigned to the training dataset, defaults to 0.8\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_and_test_data : tuple(\n",
    "        np.array[samples, width * height], np.array[samples, classes]\n",
    "        np.array[samples, width * height], np.array[samples, classes]\n",
    "    )\n",
    "        a tuple with four numpy arrays containing the training data and labels as well as the test data and labels\n",
    "    \"\"\"\n",
    "    ##############\n",
    "    return the training and test data sets\n",
    "##############\n",
    "\n",
    "train_data, train_labels, test_data, test_labels = partition(preprocessed_data, preprocessed_labels)\n",
    "train_data.shape, train_labels.shape, test_data.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Fully-connected Neural Network\n",
    "\n",
    "Using the previously introduced (see [logistic regression notebook](Logistic Regression.ipynb)) Keras API for implementing a logistic regression, we may also implement fully-connected neural networks by increasing the number of neurons in one layer and adding more layers. Using the \"softmax\" activation function, we can realize a multi-class classifier with a joint output probability of 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(data, classes):\n",
    "    \"\"\"\n",
    "    Constructs a fully-connected neural network model for the given data and number of classes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.array[samples, width * height]\n",
    "        the image dataset\n",
    "    classes : int\n",
    "        the number of unique classes in the dataset\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : keras.Model\n",
    "        the fully-connected neural network\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    ##############\n",
    "    add all the layers\n",
    "    ##############\n",
    "    \n",
    "    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model(preprocessed_data, classes=preprocessed_labels.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for Model Training Progress Monitoring\n",
    "\n",
    "Keras allows basic training monitoring through the output on the standard output and some pre-implemented callback functions. We would like to have a more fine-grained tracking for the training history in order to be able closely observe the progress for each batch. To do so, we extend a default Keras Callback class with our custom implementation that track the history for training and test phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingHistory(Callback):\n",
    "    \"\"\"\n",
    "    Class for tracking the training progress/history of the neural network. Implements the keras.Callback interface.\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs):\n",
    "        self.loss = []\n",
    "        self.acc = []\n",
    "        self.validation_loss = []\n",
    "        self.validation_acc = []\n",
    "        \n",
    "    def on_batch_end(self, _, logs):\n",
    "        \"\"\"\n",
    "        Callback invoked after each training batch.\n",
    "        Should track the training loss and accuracy in the respective members.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        _ : int\n",
    "            unused, int corresponding to the batch number\n",
    "        logs : dict{str -> float}\n",
    "            a dictionary mapping from the observed quantity to the actual valu\n",
    "        \"\"\"\n",
    "        if 'loss' in logs:\n",
    "            self.loss.append(logs['loss'])\n",
    "        if 'acc' in logs:\n",
    "            self.acc.append(logs['acc'])\n",
    "            \n",
    "    def on_epoch_end(self, _, logs):\n",
    "        if 'val_loss' in logs:\n",
    "            self.validation_loss.append(logs['val_loss'])\n",
    "        if 'val_acc' in logs:\n",
    "            self.validation_acc.append(logs['val_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Model\n",
    "\n",
    "Training a fully-connected neural network works analogous to [logistic regression](Logistic Regression.ipynb) using the Keras API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, train_labels, test_data, test_labels, epochs=50, batch_size=64):\n",
    "    \"\"\"\n",
    "    Trains a fully-connected neural network given training and test data/labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : keras.Model\n",
    "        the fully-connected neural network\n",
    "    train_data : np.array[samples, width * height]\n",
    "        the training data\n",
    "    train_labels : np.array[samples, classes]\n",
    "        the one-hot encoded training labels\n",
    "    test_data : np.array[samples, width * height]\n",
    "        the test data\n",
    "    test_labels : np.array[samples, classes]\n",
    "        the one-hot encoded test labels\n",
    "    epoch: positive int, optional\n",
    "        the number of epochs for which the neural network is trained, defaults to 50\n",
    "    batch_size: positive int, optional\n",
    "        the size of the training batches, defaults to 64\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    history : TrainingHistory\n",
    "        the tracked training and test history\n",
    "    \"\"\"\n",
    "    history = TrainingHistory()\n",
    "    ##############\n",
    "    fit the model  # also pass validation_data=(test_data, test_labels,), shuffle=True, callbacks=[history]\n",
    "    ##############\n",
    "    return history\n",
    "    \n",
    "history = train_model(model, train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the Training Progress\n",
    "\n",
    "Using the previously created and filled TrainingHistory instance, we are able to plot the loss and accuracy of the training batches and test epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \"\"\"\n",
    "    Plots the training (batch-wise) and test (epoch-wise) loss and accuracy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    history : TrainingHistory\n",
    "        an instance of TrainingHistory monitoring callback\n",
    "    \"\"\"\n",
    "    figure, (batch_axis, epoch_axis) = plt.subplots(2, 1, figsize=(16, 9), sharey=True)\n",
    "    \n",
    "    # plot the training loss and accuracy\n",
    "    batch_axis.set_xlabel('batch number')\n",
    "    training_batches = np.arange(len(history.loss))\n",
    "    \n",
    "    batch_axis.grid(False)\n",
    "    batch_axis.plot(training_batches, history.loss, color='C0', label='loss')\n",
    "    batch_axis.set_ylabel('loss')\n",
    "    \n",
    "    batch_acc_axis = batch_axis.twinx()\n",
    "    batch_acc_axis.grid(False)\n",
    "    batch_acc_axis.set_ylabel('accuracy')\n",
    "    batch_acc_axis.set_ylim(bottom=0.0)\n",
    "    batch_acc_axis.plot(training_batches, history.acc, color='C4', label='accuracy')\n",
    "    \n",
    "    # plot the training loss and accuracy\n",
    "    epoch_axis.set_xlabel('epoch number')\n",
    "    validation_epochs = np.arange(len(history.validation_loss))\n",
    "    \n",
    "    epoch_axis.grid(False)\n",
    "    epoch_axis.plot(validation_epochs, history.validation_loss, color='C0')\n",
    "    epoch_axis.set_ylabel('validation loss')\n",
    "    \n",
    "    epoch_acc_axis = epoch_axis.twinx()\n",
    "    epoch_acc_axis.grid(False)\n",
    "    epoch_acc_axis.set_ylabel('validation accuracy')\n",
    "    epoch_acc_axis.set_ylim(bottom=0.0)\n",
    "    epoch_acc_axis.plot(validation_epochs, history.validation_acc, color='C4')\n",
    "    \n",
    "    # display a legend\n",
    "    figure.legend(loc=8)\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of \"New Data\"\n",
    "\n",
    "\n",
    "Using a previously trained model, we are able to predict the classes of new \"unseen\" data. A prediction produces for each of the input data samples a 10-item long vector where each vector position contains the probability of the data item belonging to the respective class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_data, batch_size=64):\n",
    "    \"\"\"\n",
    "    Predicts for a given fully-connected neural network and a number of data samples the resulting classes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : keras.Model\n",
    "        the fully-connected neural network\n",
    "    test data : np.array[samples, width * height]\n",
    "        the data to be predicted\n",
    "    batch_size: positive int, optional\n",
    "        the size of the training batches, defaults to 64\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    prediction : np.array[samples, classes]\n",
    "        a class prediction for each class\n",
    "    \"\"\"\n",
    "    ##############\n",
    "    return all the predictions for the given data and parameters\n",
    "##############\n",
    "\n",
    "test_prediction = predict(model, test_data)\n",
    "test_prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let See Some Examples...\n",
    "\n",
    "... in order to see how well our model works. Using the predictions on the test data, we can use a bar plot to visualize all the class membership probabilities of the respective images. Green bars indicate the original true class, while red bars indicate mispredictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_prediction(data, labels, prediction, how_many=10):\n",
    "    \"\"\"\n",
    "    Visualizes for a given number of test images the class membership prediction made by our neural network.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.array[samples, width * height]\n",
    "        the test image\n",
    "    labels : np.array[samples, classes]\n",
    "        the actual one-hot encoded labels for each image\n",
    "    prediction: np.array[samples, classes]\n",
    "        the one-hot encoded predictions for each image\n",
    "    how_many : positive int, optional\n",
    "        indicates how many samples shall be displayed starting from the first, defaults to 10\n",
    "    \"\"\"\n",
    "    figure, axes = plt.subplots(how_many, 2, figsize=(12, 24))\n",
    "    digits = np.arange(labels.shape[1])\n",
    "    \n",
    "    for i in range(how_many):\n",
    "        left, right = axes[i]\n",
    "        \n",
    "        left.imshow(data[i].reshape(28, 28), cmap='gist_gray')\n",
    "        left.grid(False)\n",
    "        \n",
    "        bars = right.bar(digits, prediction[i], color='C2')\n",
    "        ##############\n",
    "        color the correct bar in green ('C1')\n",
    "        ##############\n",
    "        right.grid(False)\n",
    "        \n",
    "        right.set_xlabel('digit')\n",
    "        right.set_xticks(digits)\n",
    "        \n",
    "        right.set_ylim(0.0, 1.0)\n",
    "        right.set_ylabel('predicted probability')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "visualize_prediction(test_data, test_labels, test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where Did Things Go Wrong - The Confusion Matrix\n",
    "\n",
    "A confusion matrix is a visual way of comparing the overall predictions with the ground-truth labels. For this, a we create a class x class-sized matrix where we each position is equivalent to the relative frequency of the prediction given a particular class label. An optimal confusion matrix would result in a matrix with each of the diagonal elements equal to 1. In practice we will obviously not achieve this. Instead, with this mode of presentation we are able to judge what kind of class labels the prediction algorithm commonly confuses with other class and, potentially, take c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(labels, prediction):\n",
    "    \"\"\"\n",
    "    Computes and visualizes the confusion matrix for the test data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels : np.array[samples, classes]\n",
    "        the actual labels of the data items\n",
    "    prediction: np.array[samples, classes]\n",
    "        the corresponding predictions of the neural network\n",
    "    \"\"\"\n",
    "    classes = labels.shape[1]\n",
    "    buckets = np.arange(classes)\n",
    "    confusion = np.histogram2d(np.argmax(labels, axis=1), np.argmax(prediction, axis=1), bins=classes)[0]\n",
    "    confusion /= confusion.sum(axis=0)\n",
    "    \n",
    "    figure, axis = plt.subplots(1, figsize=(12, 12))\n",
    "    axis.grid(False)\n",
    "    image = axis.imshow(confusion, cmap='viridis')\n",
    "    axis.set_xlabel('actual')\n",
    "    axis.set_xticks(buckets)\n",
    "    axis.set_ylabel('prediction')\n",
    "    axis.set_yticks(buckets)\n",
    "    figure.colorbar(image, shrink=0.8)\n",
    "    \n",
    "    for y in range(classes):\n",
    "        for x in range(classes):\n",
    "            value = confusion[y, x]\n",
    "            color = 'white' if value <= 0.5 else 'black'\n",
    "            plt.annotate('{:.4f}'.format(float(value)), xy=(x, y), color=color, ha='center', va='center')\n",
    "            \n",
    "    plt.show()\n",
    "\n",
    "show_confusion_matrix(test_labels, test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus\n",
    "\n",
    "Try to see what the effect of stacking multiple fully-connected layers is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] **Fully-connected Neural Network**, *Venelin Valkov*, (2017), [external link](https://medium.com/@curiousily/tensorflow-for-hackers-part-iv-neural-network-from-scratch-1a4f504dfa8).\n",
    "\n",
    "[2] **One-hot**, *Wikipedia*, (2018), [external link](https://en.wikipedia.org/wiki/One-hot)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
